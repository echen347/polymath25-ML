{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1c09d40-37bf-43ad-9c55-b32fdc9102e4",
   "metadata": {},
   "source": [
    "# Documented Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "be1f642c-0aa7-42e1-a098-470ca62da85b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='mps')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cvxpy as cp\n",
    "from matplotlib.colors import LogNorm\n",
    "from scipy.special import erf, gamma\n",
    "from scipy.linalg import eigvals, eigh\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import gc\n",
    "import warnings\n",
    "\n",
    "\n",
    "\n",
    "def get_optimal_device() -> torch.device:\n",
    "    \"\"\"\n",
    "    Determine the optimal computational device for PyTorch operations.\n",
    "    Returns:\n",
    "        torch.device: The best available device in order of preference:\n",
    "                     1. CUDA (Nvidia GPUs)\n",
    "                     2. MPS (Apple Silicon GPUs)\n",
    "                     3. CPU (fallback)\n",
    "    \"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device(\"cuda\")\n",
    "    elif hasattr(torch.backends, \"mps\") and torch.backends.mps.is_available():\n",
    "        return torch.device(\"mps\")\n",
    "    else:\n",
    "        return torch.device(\"cpu\")\n",
    "\n",
    "\n",
    "# Set torch device for hardware acceleration\n",
    "device = get_optimal_device()\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6d8fa0b5-3f05-427f-a6ab-59878c703824",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Helper Functions\n",
    "def estimate_forward_KL(X, flow, log_rho_exact):\n",
    "    # Compute log-density under the exact model and flow estimate\n",
    "    log_ex = log_rho_exact(X)\n",
    "    log_est = flow.log_prob(X)\n",
    "    # Monte Carlo Estimate\n",
    "    kl_mc = np.mean(log_ex - log_est)\n",
    "    return kl_mc\n",
    "\n",
    "def preconditioned_CG(A, b, M_inv, x0=None, tol=1e-6, max_iter=1000):\n",
    "    \"\"\"\n",
    "    Solves Ax = b using the Preconditioned Conjugate Gradient (PCG) method.\n",
    "    A needs to be symmetric positive-definite, which is the case for the Hessian at local minima.\n",
    "\n",
    "    Args:\n",
    "        A (np.ndarray): The symmetric positive-definite matrix.\n",
    "        b (np.ndarray): The right-hand side vector.\n",
    "        M_inv (np.ndarray or function): The inverse of the preconditioner matrix,\n",
    "                                        or a function that computes M_inv @ r.\n",
    "        x0 (np.ndarray, optional): Initial guess for the solution. Defaults to zeros.\n",
    "        tol (float, optional): Tolerance for convergence.\n",
    "        max_iter (int, optional): Maximum number of iterations.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: The solution vector x.\n",
    "    \"\"\"\n",
    "    n = len(b)\n",
    "\n",
    "    # Initialize solution vector x\n",
    "    if x0 is None:\n",
    "        x = np.zeros(n)\n",
    "    else:\n",
    "        x = x0\n",
    "\n",
    "    # Initial residual (r = b - Ax)\n",
    "    r = b - A @ x\n",
    "    \n",
    "    # Apply the preconditioner: z = M^{-1}r\n",
    "    # This is the key difference from standard CG\n",
    "    if callable(M_inv):\n",
    "        z = M_inv(r)\n",
    "    else:\n",
    "        z = M_inv @ r\n",
    "    \n",
    "    # Initial search direction (p = z)\n",
    "    p = z.copy()\n",
    "    \n",
    "    # Dot product for later use\n",
    "    rz_old = np.dot(r, z)\n",
    "\n",
    "    for i in range(max_iter):\n",
    "        # Calculate matrix-vector product Ap\n",
    "        Ap = A @ p\n",
    "        \n",
    "        # Calculate step size alpha\n",
    "        alpha = rz_old / np.dot(p, Ap)\n",
    "        \n",
    "        # Update solution: x_{k+1} = x_k + alpha * p_k\n",
    "        x = x + alpha * p\n",
    "        \n",
    "        # Update residual: r_{k+1} = r_k - alpha * Ap_k\n",
    "        r_new = r - alpha * Ap\n",
    "        \n",
    "        # Check for convergence using the norm of the unpreconditioned residual\n",
    "        if np.linalg.norm(r_new) < tol:\n",
    "            print(f\"Converged after {i+1} iterations.\")\n",
    "            break\n",
    "            \n",
    "        # Apply the preconditioner: z_{k+1} = M^{-1}r_{k+1}\n",
    "        if callable(M_inv):\n",
    "            z_new = M_inv(r_new)\n",
    "        else:\n",
    "            z_new = M_inv @ r_new\n",
    "        \n",
    "        # Calculate new dot product\n",
    "        rz_new = np.dot(r_new, z_new)\n",
    "        \n",
    "        # Update search direction: p_{k+1} = z_{k+1} + beta * p_k\n",
    "        beta = rz_new / rz_old\n",
    "        p = z_new + beta * p\n",
    "        \n",
    "        # Update variables for next iteration\n",
    "        r = r_new\n",
    "        z = z_new\n",
    "        rz_old = rz_new\n",
    "    else:\n",
    "        print(\"Did not converge within the maximum number of iterations.\")\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "10f5ab9a-5387-4fe4-b029-80f694ec5927",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# ICNN model class\n",
    "\n",
    "class ICNN(nn.Module):\n",
    "    def __init__(self, n_dim, hidden_dims, alpha=1.0):\n",
    "        \"\"\"\n",
    "        Initializes the ICNN.\n",
    "\n",
    "        Args:\n",
    "            n_dim (int): The output dimension.\n",
    "            hidden_dims (list:ints): Dimensions of hidden layers.\n",
    "            alpha (float): The length-scale of the model.\n",
    "        \"\"\"\n",
    "        super(ICNN, self).__init__()\n",
    "        self.n_dim = n_dim\n",
    "        self.hidden_dims = hidden_dims\n",
    "        self.alpha = 1.0\n",
    "\n",
    "        self.Wx_layers = nn.ModuleList()\n",
    "        self.Wz_layers = nn.ModuleList()\n",
    "        self.b = nn.ParameterList()\n",
    "\n",
    "\n",
    "        prev_dim = 0\n",
    "        for idx, hidden_dim in enumerate(hidden_dims):\n",
    "            wx = nn.Linear(n_dim, hidden_dim)\n",
    "            wz = nn.Linear(prev_dim, hidden_dim)\n",
    "\n",
    "            if idx == 0:\n",
    "                with torch.no_grad():\n",
    "                    wz.weight.zero_()\n",
    "\n",
    "            self.Wx_layers.append(wx)\n",
    "            self.Wz_layers.append(wz)\n",
    "            self.b.append(nn.Parameter(torch.zeros(hidden_dim)))\n",
    "\n",
    "            prev_dim = hidden_dim\n",
    "        self.output_layer = nn.Linear(hidden_dims[-1], 1, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = None\n",
    "        quadratic_term = self.alpha / 2 * torch.sum(x ** 2, dim=-1, keepdim=True)\n",
    "        for i in range(len(self.hidden_dims)):\n",
    "            wx_x = self.Wx_layers[i](x)\n",
    "            if i == 0:\n",
    "                linear_sum = wx_x + self.b[i]\n",
    "            else:\n",
    "                wz_z = self.Wz_layers[i](z)\n",
    "                linear_sum = wx_x + wz_z + self.b[i]\n",
    "            z = F.softplus(linear_sum)\n",
    "\n",
    "        output = quadratic_term + self.output_layer(z)\n",
    "        return output\n",
    "\n",
    "    def enforce_constraints(self):\n",
    "        \"\"\"\n",
    "        Enforces the non-negativity constraint on W^(z) weights and output layer.\n",
    "        This should be called after the optimizer.step() during training.\n",
    "        \"\"\"\n",
    "        with torch.no_grad():\n",
    "            for i in range(1, len(self.Wz_layers)):\n",
    "                self.Wz_layers[i].weight.copy_(torch.abs(self.Wz_layers[i].weight))\n",
    "            # Ensure output layer weights are also non-negative\n",
    "            self.output_layer.weight.copy_(torch.abs(self.output_layer.weight))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "32d15706-73b6-47e6-b732-ed95151a76bf",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# ICNN Convex Flow class\n",
    "\n",
    "class DeepConvexFlow(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Deep convex potential flow parameterized by an input-convex neural network\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, icnn, dim, unbiased=False, no_bruteforce=True, m1=10, m2=None, rtol=0.0, atol=1e-3,\n",
    "                 bias_w1=0.0, trainable_w0=True):\n",
    "        super(DeepConvexFlow, self).__init__()\n",
    "        if m2 is None:\n",
    "            m2 = dim\n",
    "        self.icnn = icnn\n",
    "        self.no_bruteforce = no_bruteforce\n",
    "        self.rtol = rtol\n",
    "        self.atol = atol\n",
    "\n",
    "        self.w0 = torch.nn.Parameter(torch.log(torch.exp(torch.ones(1)) - 1), requires_grad=trainable_w0)\n",
    "        self.w1 = torch.nn.Parameter(torch.zeros(1) + bias_w1)\n",
    "        self.bias_w1 = bias_w1\n",
    "\n",
    "        self.m1, self.m2 = m1, m2\n",
    "        \n",
    "    def get_potential(self, x, context=None):\n",
    "        n = x.size(0)\n",
    "        if context is None:\n",
    "            icnn = self.icnn(x)\n",
    "        else:\n",
    "            icnn = self.icnn(x, context)\n",
    "        return F.softplus(self.w1) * icnn + F.softplus(self.w0) * (x.view(n, -1) ** 2).sum(1, keepdim=True) / 2\n",
    "\n",
    "    def reverse(self, y, max_iter=1000000, lr=1.0, tol=1e-12, x=None, context=None, **kwargs):\n",
    "        if x is None:\n",
    "            x = y.clone().detach().requires_grad_(True)\n",
    "\n",
    "        def closure():\n",
    "            # Solves x such that f(x) - y = 0\n",
    "            # <=> Solves x such that argmin_x F(x) - <x,y>\n",
    "            F = self.get_potential(x, context)\n",
    "            loss = torch.sum(F) - torch.sum(x * y)\n",
    "            x.grad = torch.autograd.grad(loss, x)[0].detach()\n",
    "            return loss\n",
    "\n",
    "        optimizer = torch.optim.LBFGS([x], lr=lr, line_search_fn=\"strong_wolfe\", max_iter=max_iter, tolerance_grad=tol,\n",
    "                                      tolerance_change=tol)\n",
    "\n",
    "        optimizer.step(closure)\n",
    "\n",
    "        # error_new = (self.forward_transform(x, context=context)[0] - y).abs().max().item()\n",
    "        # if error_new > math.sqrt(tol):\n",
    "        #     print('inversion error', error_new, flush=True)\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "\n",
    "        return x\n",
    "\n",
    "    def forward(self, x, context=None):\n",
    "        with torch.enable_grad():\n",
    "            x = x.clone().requires_grad_(True)\n",
    "            F = self.get_potential(x, context)\n",
    "            f = torch.autograd.grad(F.sum(), x, create_graph=True)[0]\n",
    "        return f\n",
    "\n",
    "    def forward_transform(self, x, logdet=0, context=None, extra=None):\n",
    "\n",
    "        return self.forward_transform_bruteforce(x, logdet, context=context)\n",
    "\n",
    "    def forward_transform_bruteforce(self, x, logdet=0, context=None):\n",
    "        warnings.warn('brute force')\n",
    "        bsz = x.shape[0]\n",
    "        input_shape = x.shape[1:]\n",
    "\n",
    "        with torch.enable_grad():\n",
    "            x.requires_grad_(True)\n",
    "            F = self.get_potential(x, context)\n",
    "            f = torch.autograd.grad(F.sum(), x, create_graph=True)[0]\n",
    "\n",
    "            # TODO: compute Hessian in block mode instead of row-by-row.\n",
    "            f = f.reshape(bsz, -1)\n",
    "            H = []\n",
    "            for i in range(f.shape[1]):\n",
    "                retain_graph = self.training or (i < (f.shape[1] - 1))\n",
    "                H.append(\n",
    "                    torch.autograd.grad(f[:, i].sum(), x, create_graph=self.training, retain_graph=retain_graph)[0])\n",
    "\n",
    "            # H is (bsz, dim, dim)\n",
    "            H = torch.stack(H, dim=1)\n",
    "\n",
    "        f = f.reshape(bsz, *input_shape)\n",
    "        return f, logdet + torch.slogdet(H).logabsdet\n",
    "\n",
    "    def extra_repr(self):\n",
    "        return f\"ConjGrad(rtol={self.rtol}, atol={self.atol})\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "478e9f3b-d639-416f-a1fe-d56f486c04eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RBF Convex Flow class\n",
    "\n",
    "class RBFConvexFlow:\n",
    "    def __init__(self, n_p=50, epsilon=0.5):\n",
    "        \"\"\"\n",
    "        Initializes the density estimator.\n",
    "\n",
    "        Args:\n",
    "            n_p (int): The number of points each local map should influence.\n",
    "                       This controls the resolution or \"bandwidth\" of the estimate.\n",
    "                       The default is 50.\n",
    "            epsilon (float): The maximum step size for the parameter of each map.\n",
    "                             This caps the learning rate to ensure stability.\n",
    "                             The default is 0.5.\n",
    "        \"\"\"\n",
    "        self.n_p = n_p\n",
    "        self.epsilon = epsilon\n",
    "        # Empty lists to store map parameters and KL divergence for each iteration\n",
    "        self.maps = []\n",
    "        self.preconditioning = {}\n",
    "        self.kl_history = []\n",
    "        self.l2cost = np.nan\n",
    "\n",
    "    def _volume_n_ball(self, n, radius=1):\n",
    "        \"\"\"\n",
    "        Calculates the volume of an n-ball with the specified radius,\n",
    "        or a unit ball if radius is not given.\n",
    "\n",
    "        Args:\n",
    "            n (int): The dimension of the n-ball.\n",
    "            radius (float): The radius of the n-ball.\n",
    "        \"\"\"\n",
    "        return radius**n * np.pi**(n/2) / gamma(n/2 + 1)\n",
    "\n",
    "    def _calculate_alpha(self, x0, n, m):\n",
    "        \"\"\"\n",
    "        Calculates the bandwidth alpha given a center x0, m number of points arround x0, in n dimensions.\n",
    "\n",
    "        Args:\n",
    "            x0 (float): Center of the unit n-ball\n",
    "            n (int): The dimension of the points.\n",
    "            m (int): Number of points around x0 to be influenced by alpha.\n",
    "        \"\"\"\n",
    "        omega_n = self._volume_n_ball(n)\n",
    "        alpha = (2 * np.pi)**0.5 * (omega_n**-1 * self.n_p / m)**(1/n) * np.exp(np.linalg.norm(x0)**2 / (2*n))\n",
    "        return alpha\n",
    "\n",
    "    def _radial_f(self, r, alpha):\n",
    "        \"\"\"\n",
    "        The radial localization function f(r), based on equation (24).\n",
    "        Handles the r=0 case to avoid division by zero.\n",
    "\n",
    "        Args:\n",
    "            r (np.ndarray): Array of radial distances ||x - x0||.\n",
    "            alpha (float): The length-scale of the map.\n",
    "\n",
    "        Returns:\n",
    "            np.ndarray: The value of the localization function.\n",
    "        \"\"\"\n",
    "        # Handle r=0 separately to avoid division by zero.\n",
    "        # The limit of erf(x)/x as x->0 is 2/sqrt(pi).\n",
    "        f_vals = np.zeros_like(r)\n",
    "        nonzero_r = r != 0\n",
    "        zero_r = ~nonzero_r\n",
    "\n",
    "        r_scaled = r[nonzero_r] / alpha\n",
    "        f_vals[nonzero_r] = erf(r_scaled) / r[nonzero_r]\n",
    "        f_vals[zero_r] = 2.0 / (alpha * np.sqrt(np.pi))\n",
    "        return f_vals\n",
    "\n",
    "    def _radial_f_prime(self, r, alpha):\n",
    "        \"\"\"\n",
    "        The derivative of the radial localization function, f'(r).\n",
    "        Handles the r=0 case, where the derivative is 0.\n",
    "\n",
    "        Args:\n",
    "            r (np.ndarray): Array of radial distances ||x - x0||.\n",
    "            alpha (float): The length-scale of the map.\n",
    "\n",
    "        Returns:\n",
    "            np.ndarray: The value of the derivative.\n",
    "        \"\"\"\n",
    "        f_prime_vals = np.zeros_like(r)\n",
    "        nonzero_r = r != 0\n",
    "        \n",
    "        r_nz = r[nonzero_r]\n",
    "        r_scaled = r_nz / alpha\n",
    "        \n",
    "        term1 = (2.0 / (alpha * np.sqrt(np.pi))) * np.exp(-r_scaled**2)\n",
    "        term2 = erf(r_scaled) / r_nz\n",
    "        f_prime_vals[nonzero_r] = (term1 - term2) / r_nz\n",
    "        \n",
    "        return f_prime_vals\n",
    "\n",
    "    def compute_J_prime(self, m, n, diff, r, f, f_prime):\n",
    "        # Initialize output array\n",
    "        J_prime = np.zeros((m, n, n))\n",
    "\n",
    "        # Create mask for non-zero r values\n",
    "        mask = r != 0\n",
    "\n",
    "        # Add scaled identity matrices where mask is True\n",
    "        J_prime[mask] = f[mask, None, None] * np.eye(n)\n",
    "\n",
    "        # Compute scaling factors for outer product (f_prime[i]/r[i])\n",
    "        scale = np.zeros(m)\n",
    "        scale[mask] = f_prime[mask] / r[mask]\n",
    "\n",
    "        # Compute outer products: (diff[i] @ diff[i].T) for all i, scaled by scale[i]\n",
    "        outer_products = np.einsum('mi,mj->mij', diff, diff)\n",
    "        J_prime += scale[:, None, None] * outer_products\n",
    "        return J_prime\n",
    "\n",
    "\n",
    "    def fit(self, x, log_rho_exact=None, n_steps=1000):\n",
    "        \"\"\"\n",
    "        Fits the density model to the data by building a sequence of maps.\n",
    "        \"\"\"\n",
    "        m, n = x.shape\n",
    "\n",
    "        # Starting map\n",
    "\n",
    "        # I choose to incorporate the preconditioning here because composing the preconditioning map will not impact the convexity of the primitive function.\n",
    "        mean = np.mean(x, axis=0)\n",
    "        z0 = x - mean\n",
    "        std = np.sqrt(np.mean(np.sum(z0**2, axis=1)) / n)\n",
    "        z0 /= std\n",
    "\n",
    "        z = z0.copy()\n",
    "\n",
    "        self.preconditioning = {'mean': mean, 'std': std}\n",
    "        self.maps = []\n",
    "\n",
    "\n",
    "        # This is the Jacobian matrix at each point. I initialize the matrix to the identity. We assume the Jacobian is always invertible, otherwise we cannot determine the target probability density.\n",
    "        J = np.tile(np.eye(n)[np.newaxis, ...], (m, 1, 1))\n",
    "\n",
    "        # Iterative map building\n",
    "        for i in range(n_steps):\n",
    "            # 1. Select a center x0\n",
    "            if np.random.rand() > 0.5:\n",
    "                # Pick from the actual observations at their current normalized state\n",
    "                idx = np.random.randint(m)\n",
    "                x0 = z[idx]\n",
    "            else:\n",
    "                # Sample the target normal distribution to keep x0 from becoming too large\n",
    "                x0 = np.random.randn(n)\n",
    "\n",
    "            # 2. Calculate length-scale alpha\n",
    "            alpha = self._calculate_alpha(x0, n, m)\n",
    "\n",
    "            # 3. Calculate Gradient (G) of the log likelihood.\n",
    "            diff = z0-x0\n",
    "            r = np.linalg.norm(diff, axis=1)\n",
    "            f = self._radial_f(r, alpha)\n",
    "            f_prime = self._radial_f_prime(r, alpha)\n",
    "            J_prime = self.compute_J_prime(m, n, diff, r, f, f_prime)\n",
    "            J_inverse = np.linalg.inv(J)\n",
    "            term_1 = np.einsum('kii->k', J_inverse @ J_prime)\n",
    "            term_2 = -f*np.sum(z * diff, axis=1)\n",
    "            G = np.sum(term_1 + term_2)\n",
    "\n",
    "\n",
    "\n",
    "            # 4. Calculate optimal step beta and constrain it\n",
    "            v = self.epsilon/(np.sqrt(self.epsilon**2+G**2))\n",
    "            beta = v*G\n",
    "\n",
    "            # 5. Update the Jacobian\n",
    "            J = J+beta*J_prime\n",
    "\n",
    "            # 6. Apply the map to transform the data\n",
    "            z = z + beta * f[:, np.newaxis] * (z0 - x0)\n",
    "\n",
    "\n",
    "            # 7. Store the map's parameters\n",
    "            self.maps.append({'x0': x0, 'alpha': alpha, 'beta': beta})\n",
    "\n",
    "            if log_rho_exact is not None:\n",
    "                # Estimate the KL divergence if the exact log density is provided\n",
    "                kl = estimate_forward_KL(x, self, log_rho_exact)\n",
    "                self.kl_history.append(kl)\n",
    "\n",
    "            if (i+1) % (n_steps//10) == 0:\n",
    "                if log_rho_exact is None:\n",
    "                    print(f\"Step {i+1}/{n_steps} completed\")\n",
    "                else:\n",
    "                    kl = estimate_forward_KL(x, self, log_rho_exact)\n",
    "                    print(f\"Step {i+1}/{n_steps} completed, KL estimate: {kl:.4f}\")\n",
    "\n",
    "\n",
    "        # 8. Computing the L2 cost.\n",
    "        self.l2cost = np.average(np.linalg.norm(z-x, axis=1))\n",
    "\n",
    "\n",
    "    def _transform(self, x_new):\n",
    "        \"\"\"Applies the full sequence of learned maps to new data.\"\"\"\n",
    "        if x_new.ndim == 1:\n",
    "            x_new = x_new.reshape(1, -1)\n",
    "        m, n = x_new.shape\n",
    "\n",
    "        # Apply preconditioning\n",
    "        z0 = (x_new - self.preconditioning['mean']) / self.preconditioning['std']\n",
    "\n",
    "        z = z0.copy()\n",
    "\n",
    "        # Calculate initial log Jacobian from preconditioning\n",
    "        log_J = np.full(m, -n * np.log(self.preconditioning['std']))\n",
    "\n",
    "\n",
    "        # Initialize the Jacobian matrix to the identity\n",
    "        J = np.tile(np.eye(n)[np.newaxis, ...], (m, 1, 1))\n",
    "\n",
    "        # Apply sequence of maps\n",
    "        for p in self.maps:\n",
    "            x0, alpha, beta = p['x0'], p['alpha'], p['beta']\n",
    "            diff = z0-x0\n",
    "            r = np.linalg.norm(diff, axis=1)\n",
    "            f = self._radial_f(r, alpha)\n",
    "            f_prime = self._radial_f_prime(r, alpha)\n",
    "\n",
    "\n",
    "            # Update the Jacobian Matrix\n",
    "            J_prime = self.compute_J_prime(m, n, diff, r, f, f_prime)\n",
    "            J = J+beta*J_prime\n",
    "\n",
    "            # Apply the map\n",
    "            z = z + beta * f[:, np.newaxis] * diff\n",
    "\n",
    "        abs_det_J = np.abs(np.linalg.det(J))\n",
    "        log_J += np.log(abs_det_J)\n",
    "\n",
    "\n",
    "        return z, log_J\n",
    "\n",
    "    def log_prob(self, x_new):\n",
    "        \"\"\"\n",
    "        Calculates the log probability density log(rho(x)) for new data points.\n",
    "\n",
    "        Args:\n",
    "            x_new (np.ndarray): New data points, shape (m, n).\n",
    "\n",
    "        Returns:\n",
    "            np.ndarray: The log probability for each point.\n",
    "        \"\"\"\n",
    "        m, n = x_new.shape\n",
    "\n",
    "        # Transform data to the target distribution space (y) and get log Jacobian\n",
    "        y, log_J = self._transform(x_new)\n",
    "\n",
    "        # Calculate log probability in the target Gaussian space\n",
    "        log_prob_gaussian = -0.5 * np.sum(y**2, axis=1) - 0.5 * n * np.log(2 * np.pi)\n",
    "\n",
    "        # Final log probability is log(rho(x)) = log(mu(y(x))) + log(J(x))\n",
    "        return log_prob_gaussian + log_J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "9aeadc94-c332-4d2d-95b9-454400f48f52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 100/1000 completed, KL estimate: 0.9011\n",
      "Step 200/1000 completed, KL estimate: 0.7014\n",
      "Step 300/1000 completed, KL estimate: 0.5447\n",
      "Step 400/1000 completed, KL estimate: 0.4782\n",
      "Step 500/1000 completed, KL estimate: 0.3814\n",
      "Step 600/1000 completed, KL estimate: 0.3116\n",
      "Step 700/1000 completed, KL estimate: 0.2625\n",
      "Step 800/1000 completed, KL estimate: 0.2570\n",
      "Step 900/1000 completed, KL estimate: 0.2199\n",
      "Step 1000/1000 completed, KL estimate: 0.2149\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'RBFConvexFlow' object has no attribute 'sample'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[110], line 46\u001b[0m\n\u001b[1;32m     43\u001b[0m n_steps \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1000\u001b[39m  \u001b[38;5;66;03m# Number of steps to fit the model\u001b[39;00m\n\u001b[1;32m     44\u001b[0m flow\u001b[38;5;241m.\u001b[39mfit(x\u001b[38;5;241m=\u001b[39mX, log_rho_exact\u001b[38;5;241m=\u001b[39mlog_rho_exact_banana, n_steps\u001b[38;5;241m=\u001b[39mn_steps)\n\u001b[0;32m---> 46\u001b[0m samples \u001b[38;5;241m=\u001b[39m flow\u001b[38;5;241m.\u001b[39msample(\u001b[38;5;241m1000\u001b[39m)  \u001b[38;5;66;03m# Generate samples from the learned density model\u001b[39;00m\n\u001b[1;32m     48\u001b[0m plt\u001b[38;5;241m.\u001b[39mscatter(samples[:, \u001b[38;5;241m0\u001b[39m], samples[:, \u001b[38;5;241m1\u001b[39m], s\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSampled Points\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     49\u001b[0m plt\u001b[38;5;241m.\u001b[39mscatter(X[:, \u001b[38;5;241m0\u001b[39m], X[:, \u001b[38;5;241m1\u001b[39m], s\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m, color\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mred\u001b[39m\u001b[38;5;124m'\u001b[39m, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOriginal Points\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'RBFConvexFlow' object has no attribute 'sample'"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Example 1: Banana\n",
    "def sample_banana(n_samples=1000, sigma=1.0, noise=0.2):\n",
    "    '''\n",
    "    Samples a banana shaped-distribution.\n",
    "\n",
    "    Args:\n",
    "        n_samples (int): Number of samples.\n",
    "        sigma (float): Standard Deviation of x-values of points.\n",
    "        noise (float): Standard deviation of noise in y-values of points.\n",
    "    '''\n",
    "    u = np.random.normal(0, sigma, size=n_samples)\n",
    "    x1 = u\n",
    "    x2 = (u**2)/4 + np.random.normal(0, noise, size=n_samples)\n",
    "    return np.stack([x1, x2], axis=1)\n",
    "\n",
    "def log_rho_exact_banana(xy, sigma=1.0, noise=0.2):\n",
    "    \"\"\"\n",
    "    Calculates the exact log-probability density for the banana distribution.\n",
    "    \n",
    "    Args:\n",
    "        xy (np.ndarray): Array of 2D points with shape (n_samples, 2).\n",
    "        sigma (float): Standard Deviation of x-values of points.\n",
    "        noise (float): Standard deviation of noise in y-values of points.\n",
    "        \n",
    "    Returns:\n",
    "        np.ndarray: The log-probability for each point.\n",
    "    \"\"\"\n",
    "    x1 = xy[:, 0]\n",
    "    x2 = xy[:, 1]\n",
    "    \n",
    "    log_p = (-np.log(2 * np.pi * sigma * noise) -\n",
    "             (x1**2) / (2 * sigma**2) -\n",
    "             (x2 - (x1**2) / 4)**2 / (2 * noise**2))\n",
    "             \n",
    "    return log_p\n",
    "\n",
    "# Sample data\n",
    "X = sample_banana()\n",
    "plt.scatter(X[:,0], X[:,1])\n",
    "\n",
    "# RBF Flow\n",
    "print(\"RBF Flow Training\\n\")\n",
    "flow = RBFConvexFlow(n_p=500, epsilon=0.08)\n",
    "n_steps = 1000  # Number of steps to fit the model\n",
    "flow.fit(x=X, log_rho_exact=log_rho_exact_banana, n_steps=n_steps)\n",
    "\n",
    "samples = flow.sample(1000)  # Generate samples from the learned density model\n",
    "\n",
    "plt.scatter(samples[:, 0], samples[:, 1], s=1, alpha=0.5, label='Sampled Points')\n",
    "plt.scatter(X[:, 0], X[:, 1], s=1, alpha=0.5, color='red', label='Original Points')\n",
    "plt.title('Samples from the RBF Model')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.legend()\n",
    "\n",
    "# ICNN Flow\n",
    "print(\"\\nICNN Flow Training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9974e8af-6fa6-46a0-a9ad-f98472262eb9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
